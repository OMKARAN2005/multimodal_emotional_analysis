# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HzDah6uRWYpJbXk06Zw937-mz3Fn_gIM
"""

pip install transformers torchaudio librosa soundfile

import torch
import torchaudio
import librosa
import numpy as np
import soundfile as sf
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC

# Load pre-trained Wav2Vec2 model and tokenizer
print("Loading Wav2Vec2 model...")
tokenizer = Wav2Vec2Tokenizer.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")
model.eval()

# Homophone dictionary
homophones = {
    "to": ["too", "two"],
    "two": ["too", "to"],
    "too": ["to", "two"],
    "their": ["there", "they're"],
    "there": ["their", "they're"],
    "they're": ["their", "there"],
    "bare": ["bear"],
    "bear": ["bare"],
    "right": ["write"],
    "write": ["right"],
    "flour": ["flower"],
    "flower": ["flour"]
}

# Add synthetic noise
def add_noise(audio, noise_level=0.05):
    noise = np.random.randn(len(audio))
    noisy_audio = audio + noise_level * noise
    return np.clip(noisy_audio, -1.0, 1.0)

# Load audio file
def load_audio(file_path, sr=16000):
    audio, sample_rate = librosa.load(file_path, sr=sr)
    return audio

# Save noisy audio (optional)
def save_audio(audio, file_path, sr=16000):
    sf.write(file_path, audio, sr)

# Transcribe using Wav2Vec2
def transcribe(audio, sample_rate=16000):
    input_values = tokenizer(audio, return_tensors="pt", padding="longest").input_values
    with torch.no_grad():
        logits = model(input_values).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = tokenizer.batch_decode(predicted_ids)[0]
    return transcription

# Detect homophones in text
def find_homophones_in_text(text):
    words = text.lower().split()
    found = {}
    for word in words:
        if word in homophones:
            found[word] = homophones[word]
    return found

# Visualize word frequencies
def visualize_word_counts(text):
    words = text.lower().split()
    word_counts = Counter(words)
    top_words = word_counts.most_common(10)

    words_plot, counts = zip(*top_words)
    plt.figure(figsize=(10, 5))
    plt.bar(words_plot, counts, color='skyblue')
    plt.title("Top 10 Word Frequencies")
    plt.xlabel("Words")
    plt.ylabel("Count")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    return word_counts

# Generate word cloud
def generate_wordcloud(word_counts):
    wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)
    plt.figure(figsize=(12, 6))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis("off")
    plt.title("WordCloud from Transcription")
    plt.show()

# Visualize homophones found
def visualize_homophones(homophone_dict):
    if not homophone_dict:
        print("No homophones to visualize.")
        return

    words = list(homophone_dict.keys())
    related = [", ".join(v) for v in homophone_dict.values()]

    plt.figure(figsize=(10, 5))
    plt.bar(words, range(len(words)), tick_label=related, color='orange')
    plt.title("Homophones Found")
    plt.xlabel("Word (→ Homophones)")
    plt.ylabel("Position Index")
    plt.tight_layout()
    plt.show()

# Main processing pipeline
def main():
    input_path = "/content/hardvard.wav"  # Change path to your WAV file
    sr = 16000

    print("Loading audio...")
    audio = load_audio(input_path, sr)

    print("Adding noise...")
    noisy_audio = add_noise(audio, noise_level=0.05)
    save_audio(noisy_audio, "/content/noisy_output.wav", sr)

    print("Transcribing...")
    transcription = transcribe(noisy_audio, sr)
    print("\nTranscription Output:\n", transcription)

    print("\nPerforming EDA and Visualization...")
    word_counts = visualize_word_counts(transcription)
    generate_wordcloud(word_counts)

    print("\nDetecting Homophones...")
    homophone_matches = find_homophones_in_text(transcription)
    if homophone_matches:
        for word, homs in homophone_matches.items():
            print(f"{word} → {', '.join(homs)}")
        visualize_homophones(homophone_matches)
    else:
        print("No homophones found.")

# Run
if __name__ == "__main__":
    main()